{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad8b0feffaddac686389c323e8f7b862",
     "grade": false,
     "grade_id": "cell-5690119ead85e67e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Checklist for submission\n",
    "\n",
    "It is extremely important to make sure that:\n",
    "\n",
    "1. Everything runs as expected (no bugs when running cells);\n",
    "2. The output from each cell corresponds to its code (don't change any cell's contents without rerunning it afterwards);\n",
    "3. All outputs are present (don't delete any of the outputs);\n",
    "4. Fill in all the places that say `# YOUR CODE HERE`, or \"**Your answer:** (fill in here)\".\n",
    "5. Never copy/paste any notebook cells. Inserting new cells is allowed, but it should not be necessary.\n",
    "6. The notebook contains some hidden metadata which is important during our grading process. **Make sure not to corrupt any of this metadata!** The metadata may for example be corrupted if you copy/paste any notebook cells, or if you perform an unsuccessful git merge / git pull. It may also be pruned completely if using Google Colab, so watch out for this. Searching for \"nbgrader\" when opening the notebook in a text editor should take you to the important metadata entries.\n",
    "7. Although we will try our very best to avoid this, it may happen that bugs are found after an assignment is released, and that we will push an updated version of the assignment to GitHub. If this happens, it is important that you update to the new version, while making sure the notebook metadata is properly updated as well. The safest way to make sure nothing gets messed up is to start from scratch on a clean updated version of the notebook, copy/pasting your code from the cells of the previous version into the cells of the new version.\n",
    "8. If you need to have multiple parallel versions of this notebook, make sure not to move them to another directory.\n",
    "9. Although not forced to work exclusively in the course `conda` environment, you need to make sure that the notebook will run in that environment, i.e. that you have not added any additional dependencies.\n",
    "\n",
    "Failing to meet any of these requirements might lead to a request for resubmission if the errors are serious enough.\n",
    "\n",
    "We advise you to perform the following steps before submission to ensure that requirements 1, 2, and 3 are always met: **Restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). This might require a bit of time, so plan ahead for this (and possibly use a cloud GPU in HA1 and HA2 for this step). Finally press the \"Save and Checkout\" button before handing in, to make sure that all your changes are saved to this .ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6bb874a16c1ff767ac0f37ce0491265",
     "grade": false,
     "grade_id": "cell-774c93bf6433de68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Fill in name of notebook file\n",
    "This might seem silly, but the version check below needs to know the filename of the current notebook, which is not trivial to find out programmatically.\n",
    "\n",
    "You might want to have several parallel versions of the notebook, and it is fine to rename the notebook as long as it stays in the same directory. **However**, if you do rename it, you also need to update its own filename below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fname = \"XXX.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "270e43e75da54d7fb8afbda64083f4e3",
     "grade": false,
     "grade_id": "cell-5676bcf768a7f9be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Fill in group number and member names (use NAME2 and GROUP only for HA1 and HA2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME1 = \"\"\n",
    "NAME2 = \"\"\n",
    "GROUP = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42f960a95815e1aa3ce8132fcec59cd9",
     "grade": false,
     "grade_id": "cell-a15fe781533d9590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Check Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72b2403e87a33f87371b150984248355",
     "grade": false,
     "grade_id": "cell-2b9c2390ee464c39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from platform import python_version_tuple\n",
    "\n",
    "assert (\n",
    "    python_version_tuple()[:2] == (\"3\", \"11\")\n",
    "), \"You are not running Python 3.11. Make sure to run Python through the course Conda environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15ec4309f1e85f6e17bda73b9b6f48a2",
     "grade": false,
     "grade_id": "cell-4869b45600ce82f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Check that notebook server has access to all required resources, and that notebook has not moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c741699084b67aa21d06ff931465b378",
     "grade": false,
     "grade_id": "cell-122ac3d9100b8afb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "nb_dirname = os.path.abspath(\"\")\n",
    "assignment_name = os.path.basename(nb_dirname)\n",
    "assert assignment_name in [\n",
    "    \"IHA1\",\n",
    "    \"IHA2\",\n",
    "    \"HA1\",\n",
    "    \"HA2\",\n",
    "], \"[ERROR] The notebook appears to have been moved from its original directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f09f40b5350db83232189137c550f0a1",
     "grade": false,
     "grade_id": "cell-2455deee513cd39c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Verify correct nb_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1709bd6d2b55a83969e44d70763b1167",
     "grade": false,
     "grade_id": "cell-0472e2fd710f1d72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        HTML(\n",
    "            r'<script>if(\"{nb_fname}\" != IPython.notebook.notebook_name) {{ alert(\"You have filled in nb_fname = \\\"{nb_fname}\\\", but this does not seem to match the notebook filename \\\"\" + IPython.notebook.notebook_name + \"\\\".\"); }}</script>'.format(\n",
    "                nb_fname=nb_fname\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "except NameError:\n",
    "    assert False, \"Make sure to fill in the nb_fname variable above!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98d88d8e8da19693053764f29dcc591d",
     "grade": false,
     "grade_id": "cell-ceacb1adcae4783d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Verify that your notebook is up-to-date and not corrupted in any way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f405c9cd7b9720915f79dba54c89375",
     "grade": false,
     "grade_id": "cell-f5a59288e11b4aec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ha_utils import check_notebook_uptodate_and_not_corrupted\n",
    "\n",
    "check_notebook_uptodate_and_not_corrupted(nb_dirname, nb_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a3d4c3586543ada9e989a70ca0b714f",
     "grade": false,
     "grade_id": "cell-64e1db7b9018bb3c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# HA2 - Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1f3cc744f92fcb4b30a4225a2c17ab3",
     "grade": false,
     "grade_id": "cell-2a56acd8b54adbc7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "This assignment is divided into two parts. In the first one, you will implement a vanilla RNN module from scratch using PyTorch to perform the task of predicting the nationality of a given name. In the second, you will implement many of the components in a Transformer block, and use it to classify movie reviews as positive or negative. \n",
    "\n",
    "For efficient use of GPU hours, you can do all development up until the training on a CPU. You can then run the training on a GPU for faster training times.\n",
    "\n",
    "**IMPORTANT NOTES:**\n",
    "Some cells contain compiled tests. For them to work propery, make sure to keep function and class names.\n",
    "Similarly to IHA1, IHA2 and HA1 some questions in this notebook will not be graded in detail, but we still expect you to answer them. Those questions are marked with (0 points) and, as well as the other questions in this notebook, they may appear in the Inspera test.\n",
    "You wonâ€™t need to train neural networks in Inspera test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0211d80b78a04b91a6d12b55523a0e9",
     "grade": false,
     "grade_id": "cell-a7a1fe5598d08eae",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 1 - Predicting Nationalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6d2792c8867f0fd983839444067a2e1",
     "grade": false,
     "grade_id": "cell-aad0c935c03346c9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In this task, you will create an RNN module using PyTorch, and train it to predict the nationality of a given input name. Your RNN will process each character of an input name at a time, and at the last character output a probability mass function over the possible countries.\n",
    "\n",
    "The data for this task is present in the file `data/nam_dict.txt`. After parsing it we will have around 44k names from 41 different countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99ee7d8dca2ac6452dc76adb1cfdad69",
     "grade": false,
     "grade_id": "cell-781c35fef278ad47",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 1.0 Imports\n",
    "\n",
    "Import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89b8102fc1277bd1cc1be94ba4154d7",
     "grade": false,
     "grade_id": "cell-7c9a70be36d77bde",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from utils.tests import ha2_part1_tests\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.load_names import get_data_from_file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fa0ba3dbc41c053ec902d862c71d552",
     "grade": false,
     "grade_id": "cell-9261caa7ba2cd0c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## 1.1 Loading the data\n",
    "\n",
    "We'll start by loading the data from the `nam_dict.txt` file, using the provided method `get_data_from_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "863a7591a650e1c480e29a4b899cae95",
     "grade": false,
     "grade_id": "cell-a733558df8d25317",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "names_dict = get_data_from_file(\"data/nam_dict.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4fee1debda22500f21addcb47020a6a",
     "grade": false,
     "grade_id": "cell-e9135dcdec0407a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The newly-created variable `names_dict` is a dictionary where each country is a key, and the value is the corresponding list of names from that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a3c16d045a6e3ea16cae84c8f4039b8",
     "grade": false,
     "grade_id": "cell-2979a922e5fd9032",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "names_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a3b6f4d26929e113e7062a040683f9e",
     "grade": false,
     "grade_id": "cell-b9578aa61d75938e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "names_dict[\"Greece\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "298f96dbddf1b6528aba07514a1442de",
     "grade": false,
     "grade_id": "cell-172dd5d6a5c41971",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's look at the dataset in more detail. Plot the number of names in each country using a [bar plot](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.bar.html).\n",
    "\n",
    "*Hints*:\n",
    "\n",
    "- You can put labels in the x-axis using the method [`xticks`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.xticks.html).\n",
    "- The `xticks` method accepts a keyword argument named `rotation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a9c0c29c84537c86908dedece729b75",
     "grade": true,
     "grade_id": "cell-ff582e8e844bfb50",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d308daf32cfba1a4b85620738dac56b9",
     "grade": false,
     "grade_id": "cell-390475b6777ce344",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Is this dataset balanced? If not, which are the top-5 countries with most names?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94306b4cb0e033dcaf119982200607ad",
     "grade": true,
     "grade_id": "cell-e70912fa2bf69d84",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "501d13317da5c48c833468ae091e8689",
     "grade": false,
     "grade_id": "cell-b332445688db5846",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e9d2c3be16a91407c9403684b28ddfe",
     "grade": false,
     "grade_id": "cell-0248575eadc7e93e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will train an RNN which takes as input one character at each time-step. In order to do so, we will encode every character in the input names into a one-hot representation that is more suited to be fed to neural networks. \n",
    "\n",
    "The first thing we need to do is to decide the size of the alphabet used for the one-hot encoding. To do so, let's take a look at all the characters used in the dataset. A simple way to do so is putting all names in the same string and then using a `set` to get the unique values. We'll treat upper-case and lower-case characters as being the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09994757b29a7eef77096b060629fb89",
     "grade": false,
     "grade_id": "cell-6b58e326e17e53f5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "temp = \" \"\n",
    "for name_list in names_dict.values():\n",
    "    for name in name_list:\n",
    "        temp += name.lower()\n",
    "charset = sorted(set(temp))\n",
    "print(f\"{len(charset)} characters:\")\n",
    "charset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "249b328ceb6d494a459a29f431015f87",
     "grade": false,
     "grade_id": "cell-c28ba53b5126e2f5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will now create a function that takes as input a name and the set of characters, and outputs a `(name length) x (charset length)` tensor, with each row being a one-hot encoding of the corresponding character. Complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51c81fb473698a3b78cade844422ce6a",
     "grade": true,
     "grade_id": "cell-28b1f4faf5fe75a3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def name2tensor(name, charset):\n",
    "    name = name.lower()\n",
    "\n",
    "    tensor = None\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bb411a8abf8bd4719d6cb9c727cb92e",
     "grade": false,
     "grade_id": "cell-e58c43a41f323b55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell without changing anything to test your implementation of the above method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "183f7d1e19e84bcf926bb82da3c8e26c",
     "grade": true,
     "grade_id": "cell-06d19fac922bf8c7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ha2_part1_tests.test_name2_tensor(name2tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "668eaa23f782b9b71ac0d980a154078d",
     "grade": false,
     "grade_id": "cell-39f66ae0097c48f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us look at an example tensor for a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9cae48abfd725712542951020e62171",
     "grade": false,
     "grade_id": "cell-5d8cbbfaa7917f2c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "name2tensor(\"Ali\", charset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "413f701decf56db3bb9755f6ae80bd80",
     "grade": false,
     "grade_id": "cell-21a59eb745d70bfd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Why does the above output tensor contain a 1 at position (0,3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49c4292927f944a5edca1db964fcd7f3",
     "grade": true,
     "grade_id": "cell-39860df3e01f0204",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "891d41423f100875a0e5b7d2484c9e09",
     "grade": false,
     "grade_id": "cell-5beb6efb1f504ce2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What would happen if you try encoding the string `Lol@` using this function? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d3e67af9309e62496b8f528eead264e",
     "grade": true,
     "grade_id": "cell-613a1d700434e11a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c524e34f47ac5e1d866d8700ed07572a",
     "grade": false,
     "grade_id": "cell-fdfe2093caad0c9d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "It's definitely possible to use the tensors created with `name2tensor` to train our RNN, but in that case we would only be able to conveniently perform forward-propagation using one sample at a time.\n",
    "\n",
    "Instead, we want to batch samples together and parallelize the forward-propagation step. To do so, all samples must have the same dimensions (right now every sample has dimension `(name length) x (charset length)`, and the length of the names varies). Modify the function `name2padded_tensor` to achieve this by padding the start of the tensor with zeros, so that the output tensor always has length `target_len x (charset length)`.\n",
    "\n",
    "*Hint*:\n",
    "\n",
    "- To make it easier to catch bugs in the next parts of the assignment, make sure to raise an exception if the `target_len` is smaller than the length of the input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8b0fc38696cfe6252577ab68ea816d4",
     "grade": true,
     "grade_id": "cell-fbe880f01de97439",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def name2padded_tensor(name, target_len, charset):\n",
    "    tensor = name2tensor(name, charset)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c6ff93e9ecb20debd046b8853ec6305",
     "grade": true,
     "grade_id": "cell-22bb8ede1d7a7da2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ha2_part1_tests.test_name2padded_tensor(name2padded_tensor, charset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d028720b6a22796f064a65dfafd403d",
     "grade": false,
     "grade_id": "cell-c9657b653aeb1c93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What should be the target length for our case in this dataset? Compute it (i.e. don't hardcode it) in the cell below and save it in a variable named `target_len`, which will be used from here on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "648616943150dba84fbf4c675deb0421",
     "grade": true,
     "grade_id": "cell-ceb412223ee3e6dd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c2d4a3f078a5d709a103b98a9cb5d2e",
     "grade": true,
     "grade_id": "cell-424ebfafabf5eab4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ha2_part1_tests.test_target_len(target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "901b6c3ed25c85d2cec741ad2e575ade",
     "grade": false,
     "grade_id": "cell-0bd908b10b33e7e2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we can go through the entire dataset, encode each of the names, and save all of it in a tensor. We'll do the same with the ground-truth labels for the countries of each name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf979f4464fe40f13d5d80cc42a6d223",
     "grade": false,
     "grade_id": "cell-c41ca1beab4900d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the tensors that will hold the names and labels\n",
    "# (note that the first dimension has 0 elements, this is a way to initialize an empty tensor for concatenating later)\n",
    "xs = torch.zeros(0, target_len, len(charset))\n",
    "ys = torch.zeros(0, dtype=torch.long)\n",
    "\n",
    "for i, country in enumerate(names_dict.keys()):\n",
    "    # Apply the name2padded_tensor function to each name in this country\n",
    "    temp = map(lambda n: name2padded_tensor(n, target_len, charset), names_dict[country])\n",
    "\n",
    "    # Add a new dimension to the resulting tensors\n",
    "    temp = [name_tensor[None, :, :] for name_tensor in temp]\n",
    "\n",
    "    # Concatenate all of them along this new dimension\n",
    "    names_tensor = torch.cat(temp, dim=0)\n",
    "\n",
    "    # Add these tensors to `xs`\n",
    "    # Note that we have 44504 data pairs (x,y) where a single input x has the shape (target_len, 57),\n",
    "    # where 57 is the length of the one-hot-encoded vectors.\n",
    "    xs = torch.cat([xs, names_tensor], dim=0)\n",
    "\n",
    "    # Create tensor filled with i`s and add that to the ground-truth tensor\n",
    "    ys_for_this_country = torch.zeros(names_tensor.shape[0], dtype=torch.long) + i\n",
    "    ys = torch.cat([ys, ys_for_this_country])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59844c38d7efe88476c8c7299e4e0eb4",
     "grade": false,
     "grade_id": "cell-52dbbea6ddcef37d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84f30aec4ebb491a7b47bc37f3c4428d",
     "grade": false,
     "grade_id": "cell-7e884148f06eed5d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0ad8b82a67e3dae17a9dcf05d4886e3",
     "grade": false,
     "grade_id": "cell-0aa1483447535d5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we can create a dataset with these tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c11c5ff489587a4726ddeafa336d2265",
     "grade": false,
     "grade_id": "cell-6b352207c061f029",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "dataset = TensorDataset(xs.to(device), ys.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86cdcef7c72b84485a13de4cf47e3dde",
     "grade": false,
     "grade_id": "cell-c20e8ae6ac70f92f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "And split it in training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa085d3c85ebeb7df3d953dd39529fa2",
     "grade": false,
     "grade_id": "cell-57448454a3d5dc19",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "n_samples = len(dataset)\n",
    "n_val_samples = int(n_samples * val_ratio)\n",
    "n_test_samples = int(n_samples * test_ratio)\n",
    "n_train_samples = n_samples - n_val_samples - n_test_samples\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [n_train_samples, n_val_samples, n_test_samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3230a3031105ec405c7da983eae5a48c",
     "grade": false,
     "grade_id": "cell-485c36faf4913176",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "### 1.3 Defining the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "191773f2b5fdc1e5c7cf16dc4f141acc",
     "grade": false,
     "grade_id": "cell-b2ed39f361f618c2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we will define the model to be trained, that is, a single layer RNN. As usual, we will create a class for the model and inherit from `nn.Module`. Define in the next cell a class for an RNN that follows the equations:\n",
    "\n",
    "$$ h_t = \\text{tanh}(W_h x_t + U_h h_{t-1} + b_h) $$\n",
    "$$ y_t = \\log \\Big(\\text{Softmax}(W_y h_t + b_y)\\Big)~,$$\n",
    "\n",
    "where $h_t$ is the current hidden-state, $h_{t-1}$ is the previous hidden state, $x_t$ is the input, $y_t$ is the output, and $W_h, U_h, b_h, W_y, b_y$ are the trainable parts of the RNN. As explained before, we will use this RNN to classify names, inputting one character at each step and using the last output as the prediction for a distribution over probable countries for the name.\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "- As you're probably aware by now, PyTorch [has a layer](https://pytorch.org/docs/stable/nn.html#logsoftmax) that already applies the log and the softmax in one pass.\n",
    "- If you get errors related to size mismatches when computing the forward-propagation in your model, try reading the documentation for the specific module where the problem is occurring (e.g. [`nn.Linear`](https://pytorch.org/docs/stable/nn.html#linear)), especially the part about the expected shape of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a182aa396856b5b783e227222dcf25c7",
     "grade": true,
     "grade_id": "cell-63759a1c550cd7e1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_size     - Dimensionality of the input of this RNN.\n",
    "            hidden_size    - Dimensionality of the hidden state.\n",
    "            output_size    - Dimensionality of the output of this RNN.\n",
    "        \"\"\"\n",
    "\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        \"\"\"\n",
    "        Runs the RNN module for one time-step.\n",
    "        Inputs:\n",
    "            x              - Batch of one-hot encoded characters.\n",
    "                             Tensor of size (BATCH SIZE x CHARSET LENGTH).\n",
    "            h              - Batch of hidden states at previous time-step.\n",
    "                             Tensor of size (BATCH SIZE x `hidden_size`).\n",
    "\n",
    "        Returns:\n",
    "            y              - Batch of outputs.\n",
    "                             Tensor of size (BATCH SIZE x NUMBER OF COUNTRIES).\n",
    "            new_h          - Batch of hidden states at current time-step.\n",
    "                             Tensor of size (BATCH SIZE x `hidden_size`).\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        return y, new_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "157041d1fa12266851d7452b63b5a63f",
     "grade": false,
     "grade_id": "cell-41a6ab734e65e9e2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the following cell to test whether the shape of your outputs are correct. Note that this *only* checks the shapes and some basic ranges of outputs, not the content (one way you can check the actual computations of your network is to `print` the tensors as they pass through the layers, in order to check that the computations do what you expected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eac3e141d2a5082702550c7c1f2a58e4",
     "grade": true,
     "grade_id": "cell-0895e453938dcd22",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ha2_part1_tests.test_model_output(RNN, device, names_dict, charset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccb1831dbc8377330348c390abd9558a",
     "grade": false,
     "grade_id": "cell-f879b658d2fe97d5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Suppose we now create an RNN using the following call: `RNN(x, y, z)`. How many parameters would this model have in total?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0356f2c29e3329f580ad15f7b8710e92",
     "grade": true,
     "grade_id": "cell-d359daf8f96289bc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d5dc81f8efd4a09172a3480777b3273",
     "grade": false,
     "grade_id": "cell-e3ae784b6fd462cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will use the Adam optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32abb30aecff746e6f8450bd2585ccd9",
     "grade": false,
     "grade_id": "cell-c8087333699def0c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebc3d34a22d398e29a9b0722fe70ae76",
     "grade": false,
     "grade_id": "cell-6411a391a74a5e36",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "And, since this is a classification problem we will use the negative log-likelihood loss ([`NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss)) to train the model. We should account for the fact that our dataset is imbalanced, and one way of dealing with this problem is to assign different weights to each class in our problem. More specifically, we want to give higher weights to examples belonging to the less frequent classes and lower weights to the more frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80ad26bd89a85a4f333e9df5f01943a5",
     "grade": false,
     "grade_id": "cell-934166eac20acb50",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute weights for each class\n",
    "n_names_for_each_country = [len(v) for v in names_dict.values()]\n",
    "ns = torch.tensor(n_names_for_each_country, dtype=torch.float)\n",
    "w = 1.0 / ns\n",
    "w = w / w.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79e4f5a4e0394f400cfe53be04b61644",
     "grade": false,
     "grade_id": "cell-4f7302c348de5f1f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Declare the appropriate weight criterion using the weights defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db52e2edd7e01838703490248ce53e82",
     "grade": true,
     "grade_id": "cell-fc3ba79ea6d5f48b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define loss\n",
    "\n",
    "criterion = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "620a7870751fac8d05a0232db9e878d1",
     "grade": true,
     "grade_id": "cell-f8f0b3cee8e3e2e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ha2_part1_tests.test_criterion(criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f9861f1dac5ac53adb9829f0953b6d7",
     "grade": false,
     "grade_id": "cell-b333a7e050fbe007",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Why is it a problem that the dataset is imbalanced? What would be the consequence of not dealing with this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f9fa9a7eabdbbfe6da3d1d261cb03a0",
     "grade": true,
     "grade_id": "cell-a044d5b4e3bcf29b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10ad6732f6b08393f1ae813a52cefd8b",
     "grade": false,
     "grade_id": "cell-0611001189dd369a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Why does assigning different weights to each class solve this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "802d55ed7c144086b485fbc344a0590a",
     "grade": true,
     "grade_id": "cell-f19ff5370ea1e86d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d8c3d416d8932ccc34820a7ff4e5b89",
     "grade": false,
     "grade_id": "cell-ced0796bf818f493",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Is there any situation where *we would want* to introduce class imbalances in your dataset? How could we create such a class imbalance in a balanced dataset (without changing the dataset itself)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e072e0c0af809a362829cb55e26eaba",
     "grade": true,
     "grade_id": "cell-821c6a2fb462d2f9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e98bb8e8ccff4cf01f23e4f4bfcf0066",
     "grade": false,
     "grade_id": "cell-95508ad6a5c542b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "### 1.4 Helper functions for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58265723d45b24d2b45cf6afb91486e9",
     "grade": false,
     "grade_id": "cell-ccbb270d5fe1c30c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that we defined the optimization problem, we can start creating the code to actually solve it. The first thing that we need is a function that, given a batch of samples, computes the output of the model for every sample and the average loss across all samples. \n",
    "\n",
    "Complete the function `batch_forward_prop` to produce this behavior.\n",
    "\n",
    "*Hints*:\n",
    "\n",
    "- Initialize the hidden state to a zero Tensor for the first forward-propagation.\n",
    "- If you get errors related to size mismatches when computing the forward-propagation in your model, try reading the documentation for the specific module where the problem is occurring (e.g. [`nn.Linear`](https://pytorch.org/docs/stable/nn.html#linear)), especially the part about the expected shape of inputs and outputs.\n",
    "- If you get errors related to size mismatches when computing the loss, try reading the [documentation for it](https://pytorch.org/docs/stable/nn.html#nllloss), especially the part about the expected shape of inputs and outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d9663c7d83280e47a02cdbc20245bc8",
     "grade": true,
     "grade_id": "cell-080aad948708672d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def batch_forward_prop(rnn, xs, ys):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        rnn            - The RNN model, instance of the RNN class.\n",
    "        xs             - Batch of input words.\n",
    "                         Tensor of shape (BATCH SIZE x `target_len` x CHARSET LENGTH).\n",
    "        ys             - Batch of ground-truth labels.\n",
    "                         Tensor of  shape (BATCH_SIZE).\n",
    "\n",
    "    Returns:\n",
    "        output         - Output computed at the last character position in the batch.\n",
    "                         Tensor of shape (BATCH_SIZE x NUMBER OF COUNTRIES).\n",
    "        loss           - Value of the average loss across the predictions for this batch, later used for back-propagation.\n",
    "                         Tensor with a single element inside.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99ee062817c7b56e5180058437d2f26d",
     "grade": false,
     "grade_id": "cell-644f9d6aaa50e21c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Run the following cell to test whether the shape of your outputs are correct. Note that this *only* checks the shapes, not the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68e05c9de81e586f673092f58f0f37c1",
     "grade": true,
     "grade_id": "cell-02f7744a186b2ebe",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ha2_part1_tests.test_batch_forward_rnn(name2tensor_fn = name2tensor, \n",
    "                                       charset = charset,\n",
    "                                       RNN_model = RNN,\n",
    "                                       device = device,\n",
    "                                       batch_forward_prop_fn = batch_forward_prop,\n",
    "                                       names_dict = names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0829fc6b5254f539a66a81a3024bdfc",
     "grade": false,
     "grade_id": "cell-4010f6bcbc1e6245",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Using this function, it's straightforward to train on a single batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "134cc4165fa9ab2ba4006213a18b0658",
     "grade": false,
     "grade_id": "cell-78972c6d342b4da9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(rnn, xs, ys, optimizer):\n",
    "    # Compute the output for all samples in the batch and the average loss\n",
    "    output, loss = batch_forward_prop(rnn, xs, ys)\n",
    "\n",
    "    # Zero gradients before computing backward-propagation\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward-propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip the gradient norm (optional, helps to stabilize training)\n",
    "    nn.utils.clip_grad_norm_(rnn.parameters(), 2)\n",
    "\n",
    "    # Perform one step of optimization\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "576143bb6960f21f2b68bd6bb977a9f0",
     "grade": false,
     "grade_id": "cell-f2b194756febe3f1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will also need a function for computing metrics of interest in the validation set. In this case, we will plot both the loss and the F1-score in the validation set. The F1-score of a classifier is the [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean) of its [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall), two metrics that are more useful than accuracy for imbalanced datasets. [This blog post](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9) can help you to familiarize yourself with these new metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1df10434c9bac143fb60157528ea3e92",
     "grade": false,
     "grade_id": "cell-94021e46113ec8cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics_on_validation_set(rnn, val_dataset):\n",
    "    # Get all the input and labels in the validation set.\n",
    "    x_val, y_val = val_dataset[:]\n",
    "\n",
    "    # Perform forward-prop in the entire validation set, with autograd disabled\n",
    "    with torch.no_grad():\n",
    "        val_output, val_loss = batch_forward_prop(rnn, x_val, y_val)\n",
    "\n",
    "    # Get numpy arrays for the true labels and the predictions\n",
    "    y_true = y_val.cpu().numpy()\n",
    "    y_pred = val_output.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    # Compute precision, recall, and F-score\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    return val_loss, precision, recall, fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06672da367df025e50d1fc66d1a14015",
     "grade": false,
     "grade_id": "cell-2e37e571600c2220",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Lastly, we define a function for plotting the metrics in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdf4e2336901aed54e7380302e6250ed",
     "grade": false,
     "grade_id": "cell-2807fe4cfa2d8b29",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_metrics(fig, ax, ns, train_losses, train_fscores, val_losses, val_fscores):\n",
    "    # Plot losses\n",
    "    ax[0].clear()\n",
    "    ax[0].plot(ns, train_losses)\n",
    "    ax[0].plot(ns, val_losses)\n",
    "    ax[0].set_title(\"Loss\")\n",
    "    ax[0].legend([\"Train\", \"Validation\"])\n",
    "    ax[0].set_xlabel(\"Number of trained batches\")\n",
    "    ax[0].grid()\n",
    "\n",
    "    # Plot F1-scores\n",
    "    ax[1].clear()\n",
    "    ax[1].plot(ns, train_fscores)\n",
    "    ax[1].plot(ns, val_fscores)\n",
    "    ax[1].plot(ns, [0.3] * len(ns), \"k--\")\n",
    "    ax[1].set_title(\"Macro F1-score\")\n",
    "    ax[1].legend([\"Train\", \"Validation\", \"F1-score threshold\"])\n",
    "    ax[1].set_xlabel(\"Number of trained batches\")\n",
    "    ax[1].grid()\n",
    "\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "520a4c1ba775bfc75e1ed71009bcf6b9",
     "grade": false,
     "grade_id": "cell-2a8edc5c0c4d13d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "With these helper functions, the `train` function becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cf4fad4f70fce9bf654526c41d23839",
     "grade": false,
     "grade_id": "cell-61029512380ba880",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "%matplotlib notebook\n",
    "\n",
    "def train(rnn, n_epochs, learning_rate, batch_size, train_dataset, val_dataset):\n",
    "    # Setup the figure for plotting progress during training\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "    plt.ion()\n",
    "    plot_interval = 100\n",
    "\n",
    "    # Create arrays to average training metrics across batches\n",
    "    preds = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "\n",
    "    # Create dictionaries to hold the computed metrics in\n",
    "    train_data = {\"losses\": [], \"fscores\": []}\n",
    "    val_data = {\"losses\": [], \"fscores\": []}\n",
    "\n",
    "    optimizer = Adam(rnn.parameters(), lr=learning_rate)\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    batch_idxs = []\n",
    "\n",
    "    # Training loop\n",
    "    i_batch = 0\n",
    "    for n in range(n_epochs):\n",
    "        for i, (x_batch, y_batch) in enumerate(train_data_loader):\n",
    "            i_batch += 1\n",
    "\n",
    "            # Compute loss and outputs\n",
    "            output, loss = train_batch(rnn, x_batch, y_batch, optimizer)\n",
    "\n",
    "            # Aggregate for later averaging\n",
    "            preds += output.argmax(dim=1).cpu().tolist()\n",
    "            labels += y_batch.cpu().tolist()\n",
    "            losses.append(loss)\n",
    "\n",
    "            # Compute metrics and plot after every `plot_interval` batches\n",
    "            if i % plot_interval == 0:\n",
    "                val_loss, _, _, val_fscore = compute_metrics_on_validation_set(\n",
    "                    rnn, val_dataset\n",
    "                )\n",
    "                train_fscore = precision_recall_fscore_support(\n",
    "                    labels, preds, average=\"macro\"\n",
    "                )[2]\n",
    "\n",
    "                val_data[\"losses\"].append(val_loss.cpu())\n",
    "                val_data[\"fscores\"].append(val_fscore)\n",
    "                train_data[\"losses\"].append((sum(losses) / len(losses)).item())\n",
    "                train_data[\"fscores\"].append(train_fscore)\n",
    "                batch_idxs.append(i_batch)\n",
    "\n",
    "                preds = []\n",
    "                labels = []\n",
    "                losses = []\n",
    "\n",
    "                plot_metrics(\n",
    "                    fig,\n",
    "                    ax,\n",
    "                    batch_idxs,\n",
    "                    train_data[\"losses\"],\n",
    "                    train_data[\"fscores\"],\n",
    "                    val_data[\"losses\"],\n",
    "                    val_data[\"fscores\"],\n",
    "                )\n",
    "                \n",
    "        print(f\"Last step validation loss: {val_loss:.3f}, F1-score: {val_fscore:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f89bbf2c0e1f3ab9e64a937f8e24863",
     "grade": false,
     "grade_id": "cell-f92f1fd576a8a7cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Make sure that you completely understand the `train` function before proceeding (e.g. that we aggregate predictions from different batches and compute metrics only at a certain interval, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed3ce0a819c3e13142b67d6cda33d2a",
     "grade": false,
     "grade_id": "cell-18f5c7620b914ebd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "### 1.5 Training!\n",
    "\n",
    "Now we're ready to train the network! Create an RNN and use the `train` function to train it.\n",
    "\n",
    "*Hints*:\n",
    "\n",
    "- Tuning the hyper-parameters (number of hidden units, learning rate, batch size, etc) will take some trial-and-error. Try simple things first, and then once you manage to train them, start scaling up. Also, have in mind the bias-variance tradeoff mentioned in the lectures.\n",
    "- When tuning the learning rate, focus first on being able to decrease the training loss. Keep decreasing the learning rate until that starts happening.\n",
    "- You should use a GPU for fast training times. Using a CPU, training a network can take ~5-10 minutes with suitable hyper-parameters. With a GPU training takes ~1 minute with the same hyper-parameters.\n",
    "\n",
    "**Note:** If the interactive plots don't work, try to downgrade the notebook as following:\n",
    "\n",
    "```!pip install notebook==6.5 traitlets==5.9```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e3d64e9c5c79168399628331405b8ed",
     "grade": true,
     "grade_id": "cell-937381af9dcaf490",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78294ad9531a89a0a40160dff0fde3c4",
     "grade": true,
     "grade_id": "cell-83faff1da5d9b893",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_, _, _, fscore = compute_metrics_on_validation_set(rnn, val_dataset)\n",
    "ha2_part1_tests.test_min_f1_score(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b9a75d1841cb3935deee42a6778ca7f",
     "grade": false,
     "grade_id": "cell-09fe0d5786ed0073",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "### 1.6 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32ba20bdba94d72537d559f5d7fed869",
     "grade": false,
     "grade_id": "cell-098308391c682cd8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that our model is trained, we can evaluate its predictions on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d028367fa4f2b8e07b9f412bc0dc82cc",
     "grade": false,
     "grade_id": "cell-ee9fecbd4fc5e6cd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Get all samples from the test set\n",
    "x_test, y_test = test_dataset[:]\n",
    "\n",
    "# Compute predictions\n",
    "with torch.no_grad():\n",
    "    test_out, _ = batch_forward_prop(rnn, x_test, y_test)\n",
    "\n",
    "# Transform them into hard predictions\n",
    "preds = test_out.argmax(dim=1)\n",
    "\n",
    "# Get `preds` as a numpy array\n",
    "preds = preds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fdeb2d6a4e4a5402f0feb9554634e15",
     "grade": false,
     "grade_id": "cell-6968066e3b5b4085",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Using these predictions, we can compute the confusion matrix on the test set as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f68abbebcb2a13780a6047027944a6bb",
     "grade": false,
     "grade_id": "cell-003dfbe728ab93f4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "y_true = y_test.cpu().numpy()\n",
    "cm = confusion_matrix(y_true, preds)\n",
    "cm = cm.astype(\"float64\")\n",
    "\n",
    "# Normalize each row\n",
    "for i in range(cm.shape[0]):\n",
    "    cm[i, :] = cm[i, :] / sum(cm[i, :])\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "498ae92e6253b9951570fd782bb67f28",
     "grade": false,
     "grade_id": "cell-d0a5d53862716ff5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In order to make this easier to visualize, let's plot it as a heat map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d33a092e83dd277193478b5a5a2e0f91",
     "grade": false,
     "grade_id": "cell-0ac30bac8eee0481",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm)\n",
    "plt.xticks(range(len(names_dict)), names_dict.keys(), rotation=\"vertical\")\n",
    "plt.yticks(range(len(names_dict)), names_dict.keys())\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14a7e23780372aa63130ea55684f8406",
     "grade": false,
     "grade_id": "cell-baa17f34d2c98af3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Why did we normalize the rows of the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02945e3740619fdfadc8beb6c4036561",
     "grade": true,
     "grade_id": "cell-5e952f1af1335cd1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e96541691eb2b5d54db9e1bac00be9d",
     "grade": false,
     "grade_id": "cell-b56067b9a8f982ed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What can you conclude from this confusion matrix? Which classes are easy/hard to classify? Which classes are being confused? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "890e6d741ec9c3b7890070c0578907d0",
     "grade": true,
     "grade_id": "cell-e3597dc61426d8a3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ff548903b15da02335b1f0111ac9c4a",
     "grade": false,
     "grade_id": "cell-a1cd31c6856025a5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To end this task, we can now define a function to perform predictions on any input name we provide (as long as the name contains only characters in our character set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7559ab6ad67adfaaad3e7dcf0b846b4",
     "grade": false,
     "grade_id": "cell-07f9089a7c996db0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(name_tensor):\n",
    "    with torch.no_grad():\n",
    "        hidden = torch.zeros(1, rnn.hidden_size).to(device)\n",
    "        for i in range(name_tensor.shape[1]):\n",
    "            output, hidden = rnn(name_tensor[:, i, :], hidden)\n",
    "    return output.exp()\n",
    "\n",
    "\n",
    "def predict(input_line, charset, n_predictions=5):\n",
    "    tensor = name2tensor(input_line, charset).to(device)[None, :]\n",
    "    output = evaluate(tensor)\n",
    "\n",
    "    # Get top N categories\n",
    "    topv, topi = output.topk(n_predictions, 1, True)\n",
    "    topv, topi = topv[0], topi[0]\n",
    "\n",
    "    cats = [list(names_dict.keys())[i] for i in topi.cpu().numpy()]\n",
    "    vs = topv.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.bar(range(len(vs)), vs)\n",
    "    plt.xticks(range(len(vs)), cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec5639b99d4fa761de5b7d2c9e8b534e",
     "grade": false,
     "grade_id": "cell-ee607ec26d687e7a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Ã…sakvi\", charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b89a8c1c05f50b787836b23459bd462",
     "grade": false,
     "grade_id": "cell-fcc84c5b71d65216",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Harakabim\", charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34252a18c101cad209f5753556a616ec",
     "grade": false,
     "grade_id": "cell-d8af5b38ed527dc0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Alakazam\", charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50cc8f27aec3a36afdd0d79160f7febd",
     "grade": false,
     "grade_id": "cell-608a1a0a87fdcfbc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Jin Quaio\", charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85c166daa739e679ef1310952e34b0d1",
     "grade": false,
     "grade_id": "cell-9e46296a62c4ad3b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Leonardino\", charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f9b4aefa09c84660877efa7bdf224d3",
     "grade": false,
     "grade_id": "cell-7107524e76e71c41",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Kim Sung\", charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf58e4845f46dacd714933e88371bf4b",
     "grade": false,
     "grade_id": "cell-e5c047f1d1960750",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Thanos\", charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50e86e915f6c85e35079ec42bd535012",
     "grade": false,
     "grade_id": "cell-fc41f7e0ab00a192",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "predict(\"Viiviika\", charset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bdf82da73d54b9f9e00cb0f323dcf206",
     "grade": false,
     "grade_id": "cell-5b8cdb44355a89df",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Experiment on new names using the next cell:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
