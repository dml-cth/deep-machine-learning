{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the project structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper notebook to create the folder structure necessary for HA1.\n",
    "Start looking at `HA1.ipynb` and revisit this notebook when needed.\n",
    "\n",
    "This should be run from the same folder where the `dogs-vs-cats.zip` file you downloaded from Kaggle is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dealing with files we use the built-in python module `Path`\n",
    "# It provides a nice abstraction of the file system, compared to working with strings only.\n",
    "# It also makes your code more portable, i.e. easier to share with someone using another operating system.\n",
    "from pathlib import Path\n",
    "# Some file system operation are not covered by 'Path' and we use 'shutil' for that\n",
    "import shutil\n",
    "\n",
    "# Regular expressions are used to find patterns in strings\n",
    "import re\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: This script assumes that you have the `dogs-vs-cats.zip` in the same directory as this notebook\n",
    "zip_file = Path.cwd() / \"dogs-vs-cats.zip\"\n",
    "if not zip_file.exists():\n",
    "    raise FileNotFoundError(\"Download and place `{}` in the current directory (`{}`)\"\n",
    "                            .format(zip_file.name, Path.cwd()))\n",
    "\n",
    "# This is a list of all the directories and files this notebook will produce.\n",
    "# If you have run this before, we will delete them and start over from `dogs-vs-cats.zip`\n",
    "# Notice how we use the `map` function to conveniently run `Path(<filename>)` on all strings in our list,\n",
    "# to turn them in portable filepaths.\n",
    "pre_existing_items = map(Path, [\"test1.zip\",\n",
    "                     \"test\",\n",
    "                     \"val\",\n",
    "                     \"train.zip\",\n",
    "                     \"train\",\n",
    "                     \"train_all\",\n",
    "                     \"sampleSubmission.csv\",\n",
    "                     \"small_train\",\n",
    "                     \"small_val\"\n",
    "                     ])\n",
    "\n",
    "for item in pre_existing_items:\n",
    "    if item.exists():\n",
    "        # We need to use different functions for files and directories.\n",
    "        if item.is_dir():\n",
    "            shutil.rmtree(item)\n",
    "        elif item.is_file():\n",
    "            item.unlink()\n",
    "        else:\n",
    "            print(\"Unknown item: {}, remove manually\".format(item))\n",
    "\n",
    "\n",
    "# Depending on your machine the following might take some seconds to run\n",
    "# `!unzip` runs the unzip command on your system, i.e. you must have unzip installed.\n",
    "# The `unzip` command is commonly installed but if not,\n",
    "# the command might fail and you need to unzip manually.\n",
    "!unzip -q dogs-vs-cats.zip\n",
    "!unzip -q test1.zip\n",
    "!unzip -q train.zip\n",
    "\n",
    "Path(\"test1\").rename(\"test\")\n",
    "Path(\"train\").rename(\"train_all\")\n",
    "\n",
    "\n",
    "# Remove sub zip filess\n",
    "Path(\"test1.zip\").unlink()\n",
    "Path(\"train.zip\").unlink()\n",
    "\n",
    "# Take a look at your current directory. Apart from notebook files (those ending in *.ipynb) you should see\n",
    "# dogs-vs-cats.zip\n",
    "# sampleSubmission.csv\n",
    "# test\n",
    "# train_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll examine the data inside the directory `train_all`.\n",
    "It contains files like this:\n",
    "\n",
    "```\n",
    "<id>.jpg\n",
    "<id>.jpg\n",
    "```\n",
    "where each id is on the from `<label>.<number>`, e.g. `cat.123`.\n",
    "\n",
    "Inside the directory `test` are unlabelled images\n",
    "\n",
    "```\n",
    "<id>.jpg\n",
    "```\n",
    "where each id is a single number.\n",
    "\n",
    "Predictions on these unknown images is what you would submit to participate in the contest.\n",
    "\n",
    "Let's count them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_all_path = Path.cwd() / \"train_all\"\n",
    "\n",
    "# Get a list of all filenames inside (these will be used for training and validation)\n",
    "# The asterisk '*' is a so called wildcard, i.e. we tell the `glob` method to find any cat/dog images,\n",
    "# regardless of their id.\n",
    "all_cat_filenames = list(train_all_path.glob(\"cat.*.jpg\"))\n",
    "all_dog_filenames = list(train_all_path.glob(\"dog.*.jpg\"))\n",
    "\n",
    "test_path = Path.cwd() / \"test\"\n",
    "all_test_filenames = list(test_path.glob(\"*.jpg\"))\n",
    "print(f\"Found {len(all_cat_filenames)} images of cats.\\nFound {len(all_dog_filenames)} images of dogs.\\nFound {len(all_test_filenames)} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create `'small_train'` and `'small_val'` folders for a smaller subset of the original dataset (the assignment asks for 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a subset of the entire training dataset (20%)\n",
    "_, few_cat_filenames, _, few_dog_filenames = train_test_split(all_cat_filenames, \n",
    "                                                              all_dog_filenames, \n",
    "                                                              test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it into training and validation sets\n",
    "split_ratio_small_dataset = 0.3\n",
    "\n",
    "few_cat_filenames_train, few_cat_filenames_val, few_dog_filenames_train, few_dog_filenames_val = \\\n",
    "train_test_split(few_cat_filenames, \n",
    "              few_dog_filenames, \n",
    "              test_size = split_ratio_small_dataset,\n",
    "              random_state = 2)\n",
    "\n",
    "print(\"The smaller dataset will be comprised of:\")\n",
    "print(f\"Training:\\t{len(few_cat_filenames_train)} cats and {len(few_dog_filenames_train)} dogs\")\n",
    "print(f\"Validation:\\t{len(few_cat_filenames_val)} cats and {len(few_dog_filenames_val)} dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and val directories and subdirectories\n",
    "subdirectories = {\"small_train/cats\": few_cat_filenames_train,\n",
    "                  \"small_train/dogs\": few_dog_filenames_train,\n",
    "                  \"small_val/cats\": few_cat_filenames_val,\n",
    "                  \"small_val/dogs\": few_dog_filenames_val\n",
    "                 }\n",
    "\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory = Path(subdirectory)\n",
    "    subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Put the training and validation data in the respective folders\n",
    "def fill_sub_dir(sub_dir, file_subset):\n",
    "    \"\"\"This function copies files from the `train_all` to a `<sub_dir>`\n",
    "    A more efficient solution would be to use \"symbolic links\" (see https://kb.iu.edu/d/abbe)\n",
    "    but for simplicity hard copies is used instead.\n",
    "    \"\"\"\n",
    "    for file in file_subset:\n",
    "        file_path = Path.cwd() / sub_dir / file.name\n",
    "        shutil.copyfile(file, file_path)\n",
    "        \n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `val` and `train` folders for the entire dataset. You need to specify the train/val split (to something reasonable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose\n",
    "split_ratio_big_dataset = 0.06\n",
    "\n",
    "if split_ratio_big_dataset is None:\n",
    "    raise ValueError(\"`split_ratio_big_dataset` must have a value between 0 and 1.\")\n",
    "\n",
    "# Split it\n",
    "all_cat_filenames_train, all_cat_filenames_val, all_dog_filenames_train, all_dog_filenames_val = \\\n",
    "train_test_split(all_cat_filenames,\n",
    "                 all_dog_filenames,\n",
    "                 test_size=split_ratio_big_dataset,\n",
    "                 random_state=3)\n",
    "\n",
    "print(\"The full dataset will be comprised of:\")\n",
    "print(f\"Train:\\t{len(all_cat_filenames_train)} cats and {len(all_dog_filenames_train)} dogs.\")\n",
    "print(f\"Val:\\t{len(all_cat_filenames_val)} cats and {len(all_dog_filenames_val)} dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and val directories and subdirectories\n",
    "subdirectories = {\"train/cats\": all_cat_filenames_train,\n",
    "                 \"train/dogs\": all_dog_filenames_train,\n",
    "                 \"val/cats\": all_cat_filenames_val,\n",
    "                 \"val/dogs\": all_dog_filenames_val\n",
    "                 }\n",
    "\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory = Path(subdirectory)\n",
    "    subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
